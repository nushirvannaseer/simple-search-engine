# -*- coding: utf-8 -*-
"""inverter.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dKHMVx0FJaHySO47fvOyMZ5B81sI7oBP
"""

#main
if __name__ == '__main__':
  doc_index_file = open('doc_index.txt', 'r')

  index_doc_list = []
  while True:
    doc_index_pair = doc_index_file.readline()
    if not doc_index_pair:
      break
    temp_pair_splitted = doc_index_pair.split('\t')
    temp_pair = f'{temp_pair_splitted[1]}\t{temp_pair_splitted[0]}\t{temp_pair_splitted[2]}'
    index_doc_list.append(temp_pair)

  index_doc_list.sort(key=lambda x: int(x.split('\t')[0]))
  temp_index_doc_list = open('term_index.txt', 'w')

  posting_list = []
  iterator = 0
  while True:
    if iterator == len(index_doc_list):
      break
    index_id = index_doc_list[iterator].split('\t')[0]
    posting = f'{index_id}'
    while index_id == index_doc_list[iterator].split('\t')[0]:
      index_doc_splitted = index_doc_list[iterator].split('\t')
      posting += f'\t{index_doc_splitted[1]}:{index_doc_splitted[2][:-1]}'

      iterator += 1
      if iterator == len(index_doc_list):
        break

    posting += '\n'
    posting_list.append(posting)
  
  temp_index_doc_list.writelines(posting_list)

  term_info_list=[]
  offset = 0
  for posting in posting_list:
    termID = posting.split('\t')[0]
    info = f'{termID}\t{offset}'
    offset += len(posting)
    post_splitted = posting.split(':')
    total_docs = len(post_splitted) - 1
    total_occurence = 0
    itr = 1
    while itr < len(post_splitted):
      total_occurence += int(post_splitted[itr].split('\t')[0])
      itr += 1
    info += f'\t{total_occurence}\t{total_docs}\n'
    term_info_list.append(info)

  term_info = open('term_info.txt', 'w')
  term_info.writelines(term_info_list)